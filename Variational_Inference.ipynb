{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Variational Inference",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5YCDDIyByqg"
      },
      "source": [
        "# Variational Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxtfZcHWscXy"
      },
      "source": [
        "Given observed data $\\mathbf{x}$ and latent variables $\\mathbf{z}$ ($\\mathbf{z}$ can be some model parameter), we are interested in approximating the posterior $p(\\mathbf{z}|\\mathbf{x})$ using a surrogate function $q(\\mathbf{z})$ that is almost as good. Assume $\\mathbf{z} \\sim p(\\mathbf{z})$ is the prior. \n",
        " \n",
        "**Aim**: minimize the KL-divergence $KL[q(\\mathbf{z}) || p(\\mathbf{z}|\\mathbf{x})] = E_{q}[\\log\\frac{q(\\mathbf{z})}{p(\\mathbf{z}|\\mathbf{x})}]$\n",
        "\n",
        "Since we don't know the posterior, derive\n",
        "\n",
        "$\n",
        "\\begin{align*}\n",
        "KL[q(\\mathbf{z}) || p(\\mathbf{z}|\\mathbf{x})] &= E_{q}[\\log\\frac{q(\\mathbf{z})}{p(\\mathbf{z}|\\mathbf{x})}] = E_{q}[\\log\\frac{q(\\mathbf{z})p(\\mathbf{x})}{p(\\mathbf{z},\\mathbf{x})}] \\\\\n",
        "&= \\underbrace{E_{q}[\\log\\frac{q(\\mathbf{z})}{p(\\mathbf{z},\\mathbf{x})}]}_{-ELBO} + \\underbrace{\\log p(\\mathbf{x})}_{\\text{evidence (fixed)}}\n",
        "\\end{align*}\n",
        "$\n",
        "\n",
        "Then we have $\\min_{q} KL = \\max_q ELBO$\n",
        "\n",
        "Note that since $KL[q(\\mathbf{z}) || p(\\mathbf{z}|\\mathbf{x})] \\ge 0$, \n",
        "we have $\\log p(\\mathbf{x}) \\ge ELBO = E_{q}[\\log\\frac{q(\\mathbf{z})}{p(\\mathbf{z},\\mathbf{x})}]$, which is the same as the derivation from Jenson's inequality. Or, from the reverse approach, we can get KL-divergence non-negative from the inequality. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YphoMSvvadjQ"
      },
      "source": [
        "## References of Variational Inference\n",
        "\n",
        "* https://arxiv.org/abs/1601.00670\n",
        "\n",
        "* https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf\n",
        "\n",
        "* https://www.youtube.com/watch?v=HxQ94L8n0vU&t=474s\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSObTWZHB8wf"
      },
      "source": [
        "# Report on previous comments\n",
        "\n",
        "This section summarizes some key points from the comments from Professor Scott Schwartz about variational inference https://github.com/pointOfive/Haining-Tan/blob/main/MADE_comments.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqP4vIiqkj0N"
      },
      "source": [
        "## Set up\n",
        "\n",
        "Model: A simple linear regression $y \\sim N(\\beta_0 + \\beta_1x, \\sigma^2)$\n",
        "\n",
        "Model parameter: ${\\theta} = (\\beta_0, \\beta_1) \\sim p(\\theta)$ prior\n",
        "\n",
        "Variational inference on the model parameter:\n",
        "\n",
        "$\n",
        "\\begin{align*}\n",
        "\\underbrace{\\log p(y)}_{\\text{Fixed marginal}} = E_q[\\log p(y|\\theta)] + \\underbrace{E_q [\\log\\frac{q(\\theta)}{p(\\theta|y)}]}_{KL[q || p(\\theta|y)]} - \\underbrace{E_q[\\log \\frac{q(\\theta)}{p(\\theta)}]}_{KL[q || p(\\theta)]}\n",
        "\\end{align*}\n",
        "$\n",
        "\n",
        "where $q(\\theta)$ is the surrogate posterior used to approximate the true posterior $p(\\theta|y)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBzKG6C0kWJp"
      },
      "source": [
        "I can see the trade-off between the three terms, but I am not sure about the second point. I think you mean the correction between the posterior and the prior, but I did not get the equation here. \n",
        "\n",
        ">2. a correction factor for wrongly integrating over $q(\\theta) \\approx p(\\theta|y) \\not = p(\\theta)$\n",
        "  - since $\\log p(y) = E_{p(\\theta)}[\\log p(y|\\theta)] \\not =  E_{p(\\theta|y)}[\\log p(y|\\theta)].$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnH-7EhZlCX2"
      },
      "source": [
        "## Implementation of DenseVariational Layer\n",
        "\n",
        "DenseVariational Layer in TFP approximates the posteror by minimizing the KL-divergence based on the variational inference equation above:\n",
        "\n",
        "$$KL[q|| p(\\theta|y)] = \\log p(y) + E_q[\\log \\frac{q(\\theta)}{p(\\theta)}] - E_q[\\log p(y|\\theta)]$$\n",
        "\n",
        "where the objective is $\\min_q E_q[\\log \\frac{q(\\theta)}{p(\\theta)}] - E_q[\\log p(y|\\theta)]$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYsMbdpxuero"
      },
      "source": [
        "* In my understanding, after approximating the posterior distribution for the model parameter $\\theta = (\\beta_0, \\beta_1)$, DenseVariational Layer draws and returns a distribution $N(\\hat\\beta_0 + \\hat\\beta_1x, \\sigma^2)$ from the posterior of $\\beta_0, \\beta_1$\n",
        "\n",
        "* TODO: loss calculation, really struggling here... Not quite see your point addressing the model.losses... \n",
        "\n",
        "* kl-weight should be averaged by the batch size since the kl-divergence is calculated by batch. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR4phxqqB2mk"
      },
      "source": [
        "# Gaussian Process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imecUVSy_L89"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors\n",
        "tfk = tfp.psd_kernels"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "bVI_2Ivc_QvN",
        "outputId": "dd1871ef-f10f-4061-b0ac-0e7825aeec29"
      },
      "source": [
        "k = 1\n",
        "b = 5\n",
        "x_min = -50\n",
        "x_max = 50\n",
        "\n",
        "n = 150\n",
        "\n",
        "def aleatoric(x): # variablity function for a particular x\n",
        "  r = (x - x_min) / (x_max - x_min)\n",
        "  return 2 * r\n",
        "\n",
        "def generate_data(n):\n",
        "  x = (x_max - x_min) * np.random.rand(n) + x_min \n",
        "  noise = np.random.randn(n) * aleatoric(x)\n",
        "  y = (k * x * (1 + np.sin(x)) + b) + noise   # add some non-linearity and noise\n",
        "  x = x[..., np.newaxis] # convert to N * 1 matrix\n",
        "  return x, y\n",
        "\n",
        "x_train, y_train = generate_data(n)\n",
        "x_test, y_test = generate_data(n)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_train, y_train, \"b.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1a39200dd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbMO-kNHckc9"
      },
      "source": [
        "TODO: will finish soon "
      ]
    }
  ]
}